import json
import uuid
import streamlit as st
import asyncio
from typing import Any, Callable, Dict, List
from utils.event_loop import initialize_event_loop, ensure_event_loop
from utils.callbacks import get_model_callback_handler

initialize_event_loop()

from langgraph.prebuilt import create_react_agent
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph.state import CompiledStateGraph
from langchain_core.runnables import RunnableConfig

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ API í‚¤ ë“±ì˜ ì„¤ì •ì„ ê°€ì ¸ì˜´)
load_dotenv(override=True)


async def astream_graph(
    graph: CompiledStateGraph,
    inputs: Dict[str, Any],
    config: RunnableConfig,
    node_names: List[str] = [],
    callback: Callable[[Dict[str, str]], None] = None,
):
    """
    Asynchronously streams the execution results of a LangGraph.

    Parameters:
    - graph (CompiledStateGraph): The compiled LangGraph to be executed.
    - inputs (dict): The input data dictionary to be passed to the graph.
    - config (RunnableConfig): Execution configuration.
    - node_names (List[str], optional): List of node names to filter output (empty list means all nodes).
    - callback (Callable[[Dict[str, str]], None], optional): A callback function for processing each chunk.
      The callback receives a dictionary with keys "node" (str) and "content" (str).

    Returns:
    - None: This function prints the streaming output but does not return any value.
    """    

    prev_node = ""

    async for chunk_msg, metadata in graph.astream(
        inputs, config, stream_mode="messages"
    ):
        curr_node = metadata["langgraph_node"]
        # Process only the specified nodes if node_names is not empty
        if not node_names or curr_node in node_names:
            if callback:
                callback({"node": curr_node, "content": chunk_msg})
            else:
                if curr_node != prev_node:
                    print("\n" + "=" * 50)
                    print(f"ğŸ”„ Node: \033[1;36m{curr_node}\033[0m ğŸ”„")
                    print("- " * 25)
                                        
            prev_node = curr_node            

# í˜ì´ì§€ ì„¤ì •: ì œëª©, ì•„ì´ì½˜, ë ˆì´ì•„ì›ƒ êµ¬ì„±
st.set_page_config(page_title="Agent with MCP Tools", page_icon="ğŸ§ ", layout="wide")

# ì‚¬ì´ë“œë°” ìµœìƒë‹¨ì— ì €ì ì •ë³´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ì´ë“œë°” ìš”ì†Œë³´ë‹¤ ë¨¼ì € ë°°ì¹˜)
st.sidebar.markdown("### âœï¸ Forked from [í…Œë””ë…¸íŠ¸](https://youtube.com/c/teddynote) | Developed by [qhdrl12](https://github.com/qhdrl12)")
st.sidebar.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

# ê¸°ì¡´ í˜ì´ì§€ íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("ğŸ¤– Agent with MCP Tools")
st.markdown("âœ¨ MCP ë„êµ¬ë¥¼ í™œìš©í•œ ReAct ì—ì´ì „íŠ¸ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False  # ì„¸ì…˜ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸
    st.session_state.agent = None  # ReAct ì—ì´ì „íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.session_state.mcp_client = None  # MCP í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.selected_model = "claude"  # ê¸°ë³¸ ëª¨ë¸ë¡œ Claude ì„¤ì •

if "thread_id" not in st.session_state:
    st.session_state.thread_id = uuid.uuid4()


# --- í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ ---
def print_message():
    """
    ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    for message in st.session_state.history:
        if message["role"] == "user":
            st.chat_message("user").markdown(message["content"])
        elif message["role"] == "assistant":
            st.chat_message("assistant").write(message["content"], unsafe_allow_html=True)
        elif message["role"] == "assistant_tool":
            with st.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                st.markdown(message["content"])


# ê¸°ì¡´ process_query í•¨ìˆ˜ë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ê³  ìƒˆë¡œìš´ ë²„ì „ ì¶”ê°€
async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        ensure_event_loop()

        if st.session_state.agent:
            # ìƒˆë¡œìš´ ì½œë°± í•¸ë“¤ëŸ¬ ì‚¬ìš©
            callback_handler = get_model_callback_handler(
                st.session_state.selected_model,
                text_placeholder,
                tool_placeholder
            )
            
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        config=RunnableConfig(
                            callbacks=[callback_handler],
                            recursion_limit=100,
                            thread_id=st.session_state.thread_id
                        ),
                    ),
                    timeout=timeout_seconds,
                )
                
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                return {"error": error_msg}, error_msg, ""
            
            final_text = "".join(callback_handler.accumulated_text)
            final_tool = "".join(callback_handler.accumulated_tool)

            return response, final_text, final_tool

        else:
            return (
                {"error": "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "",
            )
    except Exception as e:
        import traceback
        error_msg = f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""


def _create_agent_with_model(model_name: str, tools: List[Any]):
    """Creates the specific LLM and the ReAct agent."""
    prompt = "Use your tools to answer the question. Answer in Korean."
    if model_name == "claude":
        model = ChatAnthropic(
            model="claude-3-5-haiku-20241022",
            temperature=0.1,
            max_tokens=8192
        )
    elif model_name == "openai":
        model = ChatOpenAI(
            model="gpt-4o",
            temperature=0.1,
            max_tokens=4096
        )
    elif model_name == "gemini":
        model = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.1,
            max_tokens=8192
        )
    else:
        # Default to Claude
        model = ChatAnthropic(
            model="claude-3-5-haiku-20241022",
            temperature=0.1,
            max_tokens=8192
        )
    
    agent = create_react_agent(
        model,
        tools,
        checkpointer=MemorySaver(),
        prompt=prompt,
    )
    return agent


async def initialize_mcp_connection(mcp_config=None):
    """
    Initializes the MCP client connection and retrieves tools.
    Handles closing of the previous client.

    Returns:
        tuple(MultiServerMCPClient | None, List[Any] | None): 
            A tuple containing the client and tools, or (None, None) on failure.
    """
    # Close previous client if exists
    if st.session_state.mcp_client:
        try:
            print(f"ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ")
            await st.session_state.mcp_client.__aexit__(None, None, None)
            st.session_state.mcp_client = None # Clear reference after closing
        except Exception as client_exit_e:
            print(f"Error closing previous MCP client: {client_exit_e}") # Log error but continue
            st.session_state.mcp_client = None # Attempt to clear reference even if close failed

    # Create and enter new client
    try:
        with st.spinner("ğŸ”„ MCP ì„œë²„ì— ì—°ê²° ì¤‘..."):
            print("inner MCP ì„œë²„ì— ì—°ê²° ì¤‘...")
            client = MultiServerMCPClient(mcp_config)
            await client.__aenter__()
            tools = client.get_tools()
            print(f"MCP Connection successful, {len(tools)} tools retrieved.")
            return client, tools # Return client and tools
    except Exception as e:
        st.error(f"âŒ MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë˜ëŠ” ë„êµ¬ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None, None # Indicate failure


async def apply_and_reinitialize(config):
    """
    Applies the provided MCP configuration, re-initializes the MCP connection,
    and recreates the agent. Handles status updates and errors.
    """
    apply_status = st.empty()
    initialization_attempted = False # Flag to track if full init was attempted
    success = False
    try:
        with apply_status.container():
            st.warning("ğŸ”„ MCP ë„êµ¬ ì„¤ì •ì„ ì ìš©í•˜ê³  ì—ì´ì „íŠ¸ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤...")
            progress_bar = st.progress(0)
            progress_bar.progress(10)

            # Clear old state
            st.session_state.session_initialized = False
            st.session_state.agent = None
            st.session_state.tools = None
            # st.session_state.mcp_client is handled within initialize_mcp_connection

            print(f"Applying new MCP config: {config}")
            initialization_attempted = True
            
            # Initialize MCP Connection
            progress_bar.progress(30)
            new_client, new_tools = await initialize_mcp_connection(config)
            progress_bar.progress(60)

            if new_client and new_tools:
                st.session_state.mcp_client = new_client
                st.session_state.tools = new_tools # Store tools
                st.session_state.tool_count = len(new_tools)

                try:
                    # Create Agent using the current model selection
                    selected_model_name = st.session_state.selected_model
                    st.session_state.agent = _create_agent_with_model(selected_model_name, new_tools)
                    st.session_state.session_initialized = True
                    success = True
                    progress_bar.progress(100)
                    st.success("âœ… MCP ë„êµ¬ ì„¤ì • ì ìš© ë° ì—ì´ì „íŠ¸ ì¬êµ¬ì„± ì™„ë£Œ.")
                    await asyncio.sleep(2)
                    apply_status.empty()
                except Exception as agent_e:
                    progress_bar.progress(100)
                    st.error(f"âŒ ì—ì´ì „íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {agent_e}")
                    # Keep error message visible
            else:
                # initialize_mcp_connection already showed an error
                progress_bar.progress(100)
                st.error("âŒ MCP ì—°ê²° ë˜ëŠ” ë„êµ¬ ë¡œë”© ì‹¤íŒ¨ë¡œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                # Keep error message visible

    except Exception as outer_e:
        # Catch errors in the status display logic itself
        st.error(f"âŒ ì¬ì´ˆê¸°í™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(outer_e)}")
        # Attempt to clear any lingering status message if possible
        try:
            apply_status.empty()
        except: pass # Ignore cleanup errors

    # Rerun only if initialization was actually attempted and successful
    if initialization_attempted and success:
        st.rerun()
    elif not success:
         # Clear spinner/warning if it failed but didn't rerun
         try: apply_status.empty()
         except: pass


async def recreate_agent_only():
    """
    Recreates the agent using the currently selected model and existing tools.
    Assumes the MCP client connection is already valid.
    """
    
    success = False
    try:        
        st.session_state.session_initialized = False # Mark as uninitialized during agent creation
        st.session_state.agent = None # Clear old agent

        selected_model_name = st.session_state.selected_model
        tools = st.session_state.tools
        new_agent = _create_agent_with_model(selected_model_name, tools)

        st.session_state.agent = new_agent
        st.session_state.session_initialized = True
        success = True

    except Exception as e:
         st.error(f"âŒ ì—ì´ì „íŠ¸ ì¬êµ¬ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
         import traceback
         st.error(traceback.format_exc())
         # Keep error message visible
         st.session_state.session_initialized = False # Ensure state reflects failure

    # Rerun only on success, show toast first
    if success:
        st.rerun()
    else:
        pass


# --- ì‚¬ì´ë“œë°” UI: MCP ë„êµ¬ ì¶”ê°€ ì¸í„°í˜ì´ìŠ¤ë¡œ ë³€ê²½ ---
with st.sidebar.expander("MCP ë„êµ¬ ì¶”ê°€", expanded=False):
    default_config = """{
  "weather": {
    "command": "python",
    "args": ["./adapters/weather_server.py"],
    "transport": "stdio"
  }
}"""
    # pending configê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ mcp_config_text ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
    if "pending_mcp_config" not in st.session_state:
        # configs/default.json íŒŒì¼ì—ì„œ ê°’ì„ ë¡œë“œí•˜ì—¬ ì‚¬ìš©
        with open("configs/default.json", "r") as f:
            default_json = json.load(f)
            
        # default.jsonì˜ mcpServers ë‚´ìš©ì„ pending_mcp_configì— í• ë‹¹
        if "mcpServers" in default_json:
            st.session_state.pending_mcp_config = default_json["mcpServers"]
        else:
            st.session_state.pending_mcp_config = default_json
            

    # ê°œë³„ ë„êµ¬ ì¶”ê°€ë¥¼ ìœ„í•œ UI
    st.subheader("ê°œë³„ ë„êµ¬ ì¶”ê°€")
    st.markdown(
        """
    **í•˜ë‚˜ì˜ ë„êµ¬**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”:
    
    ```json
    {
      "ë„êµ¬ì´ë¦„": {
        "command": "ì‹¤í–‰ ëª…ë ¹ì–´",
        "args": ["ì¸ì1", "ì¸ì2", ...],
        "transport": "stdio"
      }
    }
    ```    
    âš ï¸ **ì¤‘ìš”**: JSONì„ ë°˜ë“œì‹œ ì¤‘ê´„í˜¸(`{}`)ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
    """
    )

    # ë³´ë‹¤ ëª…í™•í•œ ì˜ˆì‹œ ì œê³µ
    example_json = {
        "github": {
            "command": "npx",
            "args": [
                "-y",
                "@smithery/cli@latest",
                "run",
                "@smithery-ai/github",
                "--config",
                '{"githubPersonalAccessToken":"your_token_here"}',
            ],
            "transport": "stdio",
        }
    }

    default_text = json.dumps(example_json, indent=2, ensure_ascii=False)

    new_tool_json = st.text_area(
        "ë„êµ¬ JSON",
        default_text,
        height=250,
    )

    # ì¶”ê°€í•˜ê¸° ë²„íŠ¼
    if st.button(
        "ë„êµ¬ ì¶”ê°€",
        type="primary",
        key="add_tool_button",
        use_container_width=True,
    ):
        try:
            # ì…ë ¥ê°’ ê²€ì¦
            if not new_tool_json.strip().startswith(
                "{"
            ) or not new_tool_json.strip().endswith("}"):
                st.error("JSONì€ ì¤‘ê´„í˜¸({})ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ì•¼ í•©ë‹ˆë‹¤.")
                st.markdown('ì˜¬ë°”ë¥¸ í˜•ì‹: `{ "ë„êµ¬ì´ë¦„": { ... } }`')
            else:
                # JSON íŒŒì‹±
                parsed_tool = json.loads(new_tool_json)

                # mcpServers í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
                if "mcpServers" in parsed_tool:
                    # mcpServers ì•ˆì˜ ë‚´ìš©ì„ ìµœìƒìœ„ë¡œ ì´ë™
                    parsed_tool = parsed_tool["mcpServers"]
                    st.info("'mcpServers' í˜•ì‹ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

                # ì…ë ¥ëœ ë„êµ¬ ìˆ˜ í™•ì¸
                if len(parsed_tool) == 0:
                    st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë„êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    # ëª¨ë“  ë„êµ¬ì— ëŒ€í•´ ì²˜ë¦¬
                    success_tools = []
                    for tool_name, tool_config in parsed_tool.items():
                        # URL í•„ë“œ í™•ì¸ ë° transport ì„¤ì •
                        if "url" in tool_config:
                            # URLì´ ìˆëŠ” ê²½ìš° transportë¥¼ "sse"ë¡œ ì„¤ì •
                            tool_config["transport"] = "sse"
                            st.info(
                                f"'{tool_name}' ë„êµ¬ì— URLì´ ê°ì§€ë˜ì–´ transportë¥¼ 'sse'ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                            )
                        elif "transport" not in tool_config:
                            # URLì´ ì—†ê³  transportë„ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ "stdio" ì„¤ì •
                            tool_config["transport"] = "stdio"

                        # í•„ìˆ˜ í•„ë“œ í™•ì¸
                        if "command" not in tool_config and "url" not in tool_config:
                            st.error(
                                f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'command' ë˜ëŠ” 'url' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                            )
                        elif "command" in tool_config and "args" not in tool_config:
                            st.error(
                                f"'{tool_name}' ë„êµ¬ ì„¤ì •ì—ëŠ” 'args' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                            )
                        elif "command" in tool_config and not isinstance(
                            tool_config["args"], list
                        ):
                            st.error(
                                f"'{tool_name}' ë„êµ¬ì˜ 'args' í•„ë“œëŠ” ë°˜ë“œì‹œ ë°°ì—´([]) í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                            )
                        else:
                            # pending_mcp_configì— ë„êµ¬ ì¶”ê°€
                            st.session_state.pending_mcp_config[tool_name] = tool_config
                            success_tools.append(tool_name)

                    # ì„±ê³µ ë©”ì‹œì§€ ëŒ€ì‹  ì¦‰ì‹œ ì ìš©
                    if success_tools:
                        st.info(f"ì¶”ê°€ëœ ë„êµ¬: {', '.join(success_tools)}. ë³€ê²½ì‚¬í•­ ì ìš© ì¤‘...")
                        # Apply changes immediately
                        st.session_state.event_loop.run_until_complete(
                            apply_and_reinitialize(st.session_state.pending_mcp_config)
                        )
                        # Rerun happens inside apply_and_reinitialize on success

        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
            st.markdown(
                f"""
            **ìˆ˜ì • ë°©ë²•**:
            1. JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
            2. ëª¨ë“  í‚¤ëŠ” í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
            3. ë¬¸ìì—´ ê°’ë„ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
            4. ë¬¸ìì—´ ë‚´ì—ì„œ í°ë”°ì˜´í‘œë¥¼ ì‚¬ìš©í•  ê²½ìš° ì´ìŠ¤ì¼€ì´í”„(\\")í•´ì•¼ í•©ë‹ˆë‹¤.
            """
            )
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # êµ¬ë¶„ì„  ì¶”ê°€
    st.divider()

    # í˜„ì¬ ì„¤ì •ëœ ë„êµ¬ ì„¤ì • í‘œì‹œ (ì½ê¸° ì „ìš©)
    st.subheader("í˜„ì¬ ë„êµ¬ ì„¤ì • (ì½ê¸° ì „ìš©)")
    st.code(
        json.dumps(st.session_state.pending_mcp_config, indent=2, ensure_ascii=False)
    )

# --- ë“±ë¡ëœ ë„êµ¬ ëª©ë¡ í‘œì‹œ ë° ì‚­ì œ ë²„íŠ¼ ì¶”ê°€ ---
with st.sidebar.expander("ë“±ë¡ëœ ë„êµ¬ ëª©ë¡", expanded=True):
    try:
        pending_config = st.session_state.pending_mcp_config
    except Exception as e:
        st.error("ìœ íš¨í•œ MCP ë„êµ¬ ì„¤ì •ì´ ì•„ë‹™ë‹ˆë‹¤.")
    else:
        # pending configì˜ í‚¤(ë„êµ¬ ì´ë¦„) ëª©ë¡ì„ ìˆœíšŒí•˜ë©° í‘œì‹œ
        for tool_name in list(pending_config.keys()):
            col1, col2 = st.columns([8, 2])
            col1.markdown(f"- **{tool_name}**")
            if col2.button("ì‚­ì œ", key=f"delete_{tool_name}"):
                # pending configì—ì„œ í•´ë‹¹ ë„êµ¬ ì‚­ì œ (ì¦‰ì‹œ ì ìš©ë˜ì§€ëŠ” ì•ŠìŒ)
                tool_name_deleted = tool_name # Store name for message
                del st.session_state.pending_mcp_config[tool_name]
                st.info(f"{tool_name_deleted} ë„êµ¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ë³€ê²½ì‚¬í•­ ì ìš© ì¤‘...")
                # Apply changes immediately
                st.session_state.event_loop.run_until_complete(
                    apply_and_reinitialize(st.session_state.pending_mcp_config)
                )
                # Rerun happens inside apply_and_reinitialize on success


with st.sidebar:

    # ëª¨ë¸ ì„ íƒ UI ì¶”ê°€
    st.subheader("ğŸš€ ëª¨ë¸ ì„ íƒ")
    model_options = {
        "claude": "Claude 3.5 Haiku (Anthropic)",
        "openai": "GPT-4o (OpenAI)",
        "gemini": "Gemini 1.5 Pro (Google)"
    }
    
    # Get index of currently selected model, default to 0 if not found
    current_model_key = st.session_state.selected_model
    default_index = 0
    model_keys = list(model_options.keys())
    if current_model_key in model_keys:
        default_index = model_keys.index(current_model_key)

    selected_model = st.selectbox(
        "LLM ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
        model_keys,
        format_func=lambda x: model_options[x],
        index=default_index
    )
    
    # ì„ íƒëœ ëª¨ë¸ì´ ë³€ê²½ë˜ë©´ ì—ì´ì „íŠ¸ë§Œ ì¬êµ¬ì„±
    if selected_model != st.session_state.selected_model:
        st.session_state.selected_model = selected_model
        # Call the function to recreate only the agent
        st.session_state.event_loop.run_until_complete(
            recreate_agent_only()
        )
        # Rerun is handled within recreate_agent_only on success


# --- ê¸°ë³¸ ì„¸ì…˜ ì´ˆê¸°í™” (ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°) ---
if not st.session_state.session_initialized:
    st.info("ğŸ”„ MCP ì„œë²„ ì—°ê²° ë° ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    # Use the full reinitialize function for the initial setup
    st.session_state.event_loop.run_until_complete(
        apply_and_reinitialize(st.session_state.pending_mcp_config)
    )
    # apply_and_reinitialize handles success/error messages and potential rerun


# --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ---
print_message()

# --- ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬ ---
user_query = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_query:
    if st.session_state.session_initialized:
        st.chat_message("user").markdown(user_query)
        with st.chat_message("assistant"):
            tool_placeholder = st.empty()
            text_placeholder = st.empty()
            resp, final_text, final_tool = (
                st.session_state.event_loop.run_until_complete(
                    process_query(user_query, text_placeholder, tool_placeholder)
                )
            )

        print(f"chat resp: {resp}\nfinal_text: {final_text}\nfinal_tool: {final_tool}")
        if resp and "error" in resp:
            st.error(resp["error"])
        else:
            # ëª¨ë¸ë³„ íƒœê·¸ ìŠ¤íƒ€ì¼ ì •ì˜
            model_tags = {
                "claude": {"name": "Claude", "color": "orange"},
                "openai": {"name": "GPT", "color": "black"},
                "gemini": {"name": "Gemini", "color": "blue"}
            }
            
            current_model = st.session_state.selected_model
            model_info = model_tags.get(current_model, {"name": "AI", "color": "gray"})
            
            # HTML ìŠ¤íƒ€ì¼ì˜ íƒœê·¸ ìƒì„±
            model_tag = f'<span style="background-color: {model_info["color"]}; color: white; padding: 2px 8px; border-radius: 12px; font-size: 0.8em; margin-right: 8px;">{model_info["name"]}</span>'
            
            # íƒœê·¸ë¥¼ ë‹µë³€ ì•ì— ì¶”ê°€
            final_text_with_tag = f"{model_tag}{final_text}"

            st.session_state.history.append({"role": "user", "content": user_query})
            st.session_state.history.append(
                {"role": "assistant", "content": final_text_with_tag}
            )
            if final_tool.strip():
                st.session_state.history.append(
                    {"role": "assistant_tool", "content": final_tool}
                )
            st.rerun()
    else:
        st.warning("â³ ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# --- ì‚¬ì´ë“œë°”: ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ ---
with st.sidebar:
    st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
    st.write(f"ğŸ› ï¸ MCP ë„êµ¬ ìˆ˜: {st.session_state.get('tool_count', 'ì´ˆê¸°í™” ì¤‘...')}")
    
    # êµ¬ë¶„ì„  ì¶”ê°€ (ì‹œê°ì  ë¶„ë¦¬)
    st.divider()

    # ì‚¬ì´ë“œë°” ìµœí•˜ë‹¨ì— ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True, type="primary"):
        # thread_id ì´ˆê¸°í™”
        st.session_state.thread_id = uuid.uuid4()

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        st.session_state.history = []

        # ì•Œë¦¼ ë©”ì‹œì§€
        st.success("âœ… ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

        